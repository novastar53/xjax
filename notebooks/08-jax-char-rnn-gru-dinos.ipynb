{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing a Char-RNN with a GRU for Generating Dinosaur Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by reading the dinosaur names dataset and extracting all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = open(\"../datasets/dinos.txt\", \"r\").read()\n",
    "lines = text.split(\"\\n\")\n",
    "lines = [ l.strip().lower() for l in lines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like we have 1542 dinosaur names in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"Looks like we have {len(lines)} dinosaur names in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at a few dinosaur names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachenosaurus',\n",
       " 'aardonyx',\n",
       " 'abdallahsaurus',\n",
       " 'abelisaurus',\n",
       " 'abrictosaurus',\n",
       " 'abrosaurus',\n",
       " 'abydosaurus',\n",
       " 'acanthopholis',\n",
       " 'achelousaurus',\n",
       " 'acheroraptor']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long are the dinosaur names? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aachenosaurus\n",
      "abdallahsaurus\n",
      "acrocanthosaurus\n",
      "archaeodontosaurus\n",
      "carcharodontosaurus\n",
      "micropachycephalosaurus\n",
      "The longest name is micropachycephalosaurus which is 23 characters.\n",
      "The shortest name is mei which is 3 characters.\n"
     ]
    }
   ],
   "source": [
    "lengths = [ len(name) for name in lines ]\n",
    "max_len = 0\n",
    "longest_name = None\n",
    "min_len = float('inf')\n",
    "shortest_name = None\n",
    "\n",
    "for line in lines:\n",
    "    l = len(line)\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "        longest_name = line\n",
    "        print(longest_name)\n",
    "    if l < min_len:\n",
    "        min_len = l \n",
    "        shortest_name = line\n",
    "\n",
    "print(f\"The longest name is {longest_name} which is {max_len} characters.\")\n",
    "print(f\"The shortest name is {shortest_name} which is {min_len} characters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we'll be training a character RNN, let's tokenize the data by character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, generate a vocabulary\n",
    "counts = {}\n",
    "for line in lines:\n",
    "    chars = list(line)\n",
    "    for c in chars:\n",
    "        if c not in counts:\n",
    "            counts[c] = 1\n",
    "        else:\n",
    "            counts[c] += 1\n",
    "\n",
    "vocab = sorted(list(counts.keys()))\n",
    "\n",
    "VOCAB_SIZE = len(vocab) + 1\n",
    "\n",
    "# Then create token lookup indices\n",
    "tok_to_idx = {}\n",
    "idx_to_tok = {}\n",
    "\n",
    "for i,c in enumerate(vocab):\n",
    "    tok_to_idx[c] = i\n",
    "    idx_to_tok[i] = c\n",
    "\n",
    "\n",
    "# Add a stop character to the token index lookup\n",
    "tok_to_idx[\"@\"] = VOCAB_SIZE - 1\n",
    "idx_to_tok[VOCAB_SIZE - 1] = \"@\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's generate the Dataset. \n",
    "Since this is a sequence to sequence model, it has to learn to predict the next token in the sequence. Each training example therefore consists of an input sequence of tokens. The label is just the same sequence shifted to the right by a single token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "#Generate the dataset \n",
    "X = []\n",
    "Y = []\n",
    "for line in lines:\n",
    "    tokens = [ tok_to_idx[c] for c in line ] \n",
    "    tokens += [VOCAB_SIZE]*(max_len - len(tokens))\n",
    "    X.append(jnp.array([VOCAB_SIZE] + tokens))\n",
    "    Y.append(jnp.array(tokens + [VOCAB_SIZE]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's train the Char RNN model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Char RNN:epoch=0, loss=5101.4146, elapsed=1.9660\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, elapsed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# I train a character RNN model on the data \u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m trained_params \u001b[38;5;241m=\u001b[39m \u001b[43mxjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchar_rnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVOCAB_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/src/xjax/models/jax/_char_rnn.py:171\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, rng, params, X_train, Y_train, vocab_size, epochs, learning_rate, max_grad)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[1;32m    170\u001b[0m     rng, sub_rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m--> 171\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     params, optimizer_state, loss \u001b[38;5;241m=\u001b[39m step_fn(optimizer_state, params, X, Y)\n\u001b[1;32m    173\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/dev/xjax/src/xjax/models/jax/_char_rnn.py:193\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(rng, X, Y, vocab_size)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Convert to one-hot representation\u001b[39;00m\n\u001b[1;32m    192\u001b[0m x_out \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39meye(vocab_size)[X[i], :]\n\u001b[0;32m--> 193\u001b[0m y_out \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_out, y_out\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/array.py:355\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:7856\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   7853\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   7855\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m _split_index_for_jit(idx, arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m-> 7856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7857\u001b[0m \u001b[43m               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:7886\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   7884\u001b[0m \u001b[38;5;66;03m# We avoid generating a gather when indexer.gather_indices.size is empty.\u001b[39;00m\n\u001b[1;32m   7885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mis_empty_shape(indexer\u001b[38;5;241m.\u001b[39mgather_indices\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m-> 7886\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7887\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_slice_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7888\u001b[0m \u001b[43m    \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7892\u001b[0m \u001b[38;5;66;03m# Reverses axes with negative strides.\u001b[39;00m\n\u001b[1;32m   7893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39mreversed_y_dims:\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/lax/slicing.py:348\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(operand, start_indices, dimension_numbers, slice_sizes, unique_indices, indices_are_sorted, mode, fill_value)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m   fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension_numbers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/core.py:429\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    427\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    428\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 429\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/core.py:433\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    432\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 433\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/core.py:939\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:80\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     76\u001b[0m _on_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m### op-by-op execution\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_primitive\u001b[39m(prim, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m   fun \u001b[38;5;241m=\u001b[39m xla_primitive_callable(prim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import jax\n",
    "import xjax\n",
    "from xjax.signals import train_epoch_completed\n",
    "\n",
    "# Module logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"Char RNN\")\n",
    "\n",
    "# Define hyperparameters\n",
    "HIDDEN_SIZE = 64\n",
    "VOCAB_SIZE = len(tok_to_idx)\n",
    "learning_rate = 1E-2\n",
    "max_grad = 10\n",
    "epochs = 300\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "# I define a character-rnn model\n",
    "params, model = xjax.models.char_rnn.char_rnn(rng, 27, HIDDEN_SIZE)\n",
    "\n",
    "# I log events\n",
    "@train_epoch_completed.connect_via(model)\n",
    "def collect_events(_, *, epoch, loss, elapsed, **__):\n",
    "    logger.info(f\"epoch={epoch}, loss={loss:0.4f}, elapsed={elapsed:0.4f}\")\n",
    "\n",
    "# I train a character RNN model on the data \n",
    "trained_params = xjax.models.char_rnn.train(model, rng=rng, params=params, \n",
    "                                            X_train=X, Y_train=Y, \n",
    "                                            vocab_size=VOCAB_SIZE, \n",
    "                                            epochs=epochs, \n",
    "                                            learning_rate=learning_rate,\n",
    "                                            max_grad=max_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's look at what the model learned\n",
    "Ideally, the model should have learned to generate plausible-sounding dinosaur names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_str = \"bac\"\n",
    "prefix = [tok_to_idx[c] for c in prefix_str]\n",
    "generated = []\n",
    "for i in range(25):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y = xjax.models.char_rnn.generate(rng=sub_rng, prefix= prefix, params=trained_params, hidden_size=HIDDEN_SIZE, vocab_size=VOCAB_SIZE) \n",
    "    generated.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baceoromossus\n",
      "baceorodor\n",
      "bacron\n",
      "bacudochus\n",
      "baceoron\n",
      "baceurobrg\n",
      "bacuoran\n",
      "baceog\n",
      "bacurrurus\n",
      "bacroh\n",
      "bachoreruchus\n",
      "bacurnos\n",
      "baceon\n",
      "bacuon\n",
      "bacroh\n",
      "bacuhe\n",
      "bacueris\n",
      "bacyuropops\n",
      "baceorynn\n",
      "bacuho\n",
      "bacurnerus\n",
      "bacuhe\n",
      "bachorerolosaurus\n",
      "bacuinhia\n",
      "bacudoraurus\n"
     ]
    }
   ],
   "source": [
    "for g in generated:\n",
    "    print(\"\".join([idx_to_tok[i] for i in g[:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these look plausible. It seems to have figured out that dinosaur names tend to end with an 'rus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's train a single-layer GRU as our baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integer scalar arrays can be converted to a scalar index.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, valid perplexity=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_perplexity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, elapsed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# I train a GRU model on the data \u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m baseline_params \u001b[38;5;241m=\u001b[39m \u001b[43mgru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVOCAB_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_GRAD\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/xjax/src/xjax/models/jax/_gru.py:208\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, rng, params, X_train, Y_train, X_valid, Y_valid, vocab_size, batch_size, num_epochs, learning_rate, max_grad)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size):\n\u001b[1;32m    207\u001b[0m     rng, sub_rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m--> 208\u001b[0m     X_batch, Y_batch \u001b[38;5;241m=\u001b[39m \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_rng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     params, optimizer_state, loss \u001b[38;5;241m=\u001b[39m step_fn(optimizer_state, params, X_batch, Y_batch)\n\u001b[1;32m    210\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/dev/xjax/src/xjax/models/jax/_gru.py:137\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(rng, X, Y, batch_size, vocab_size)\u001b[0m\n\u001b[1;32m    134\u001b[0m idxs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(rng, (batch_size,), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X))\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Convert to one-hot representation\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m x_out \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39meye(vocab_size)[\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m, :]\n\u001b[1;32m    138\u001b[0m y_out \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39meye(vocab_size)[Y[idxs], :]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_out, y_out\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/array.py:302\u001b[0m, in \u001b[0;36mArrayImpl.__index__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__index__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 302\u001b[0m   \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_integer_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "File \u001b[0;32m~/dev/xjax/.venv/lib/python3.12/site-packages/jax/_src/core.py:659\u001b[0m, in \u001b[0;36mcheck_integer_conversion\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_integer_conversion\u001b[39m(arr: Array):\n\u001b[1;32m    658\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly integer scalar arrays can be converted to a scalar index.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integer scalar arrays can be converted to a scalar index."
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "\n",
    "from xjax.models import gru\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logger = logging.getLogger(\"GRU\")\n",
    "\n",
    "# Set up hyperparameters\n",
    "HIDDEN_SIZE=128\n",
    "EPOCHS=200\n",
    "BATCH_SIZE=128\n",
    "LEARNING_RATE = 5*10**(-3)\n",
    "MAX_GRAD = 1\n",
    "\n",
    "params, baseline_model = gru.gru(rng, vocab_size=VOCAB_SIZE, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "@train_epoch_completed.connect_via(baseline_model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_perplexity, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid perplexity={valid_perplexity:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "baseline_params = gru.train(baseline_model, rng=rng, params=params, \n",
    "                                            X_train=X, Y_train=Y, \n",
    "                                            vocab_size=VOCAB_SIZE, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
