{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Gated Recurrent Units With and Without Attention\n",
    "...by learning to predict the text of H.G. Wells' The Time Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "The Time Machine is a classic Science Fiction novel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51713"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import jax\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "\n",
    "raw_text = open('../datasets/timemachine.txt').read()\n",
    "words = raw_text.split(\" \")\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At around 51000 words, it's not a large dataset, but it is should be sufficient for traning small models with few parameters like a single layer GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize the text\n",
    "We will be using a character based tokenization scheme and ignore all punctuation and special characters. This should allow the model to learn character sequences without the additional task of learning sentences boundaries, punctuation, formatting etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = raw_text.lower()\n",
    "text = re.sub(r'[^a-z]+', ' ', text) #[:333]\n",
    "\n",
    "# Tokenize into characters\n",
    "char_tokenized_text = list(text)\n",
    "token_counts = Counter(char_tokenized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "### Generate the Vocabulary\n",
    "tok_to_idx = {}\n",
    "idx_to_tok =  list(sorted(set([tok for tok,count in token_counts.items()])))\n",
    "tok_to_idx = {tok: idx for idx, tok in enumerate(idx_to_tok)}\n",
    "\n",
    "vocab_size = len(idx_to_tok)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's generate the dataset. \n",
    "Just like in the Dinosaur Character RNN experiment, the dataset will consist of character sequences. However, this time we will use fixed-length sequences. This helps parallelize and thus speed up training.\n",
    "Additionally, we will generate overalapping sequences to augment the size of the dataset.\n",
    "To prevent overfitting, we will use a validation set during training and a test set to produce the final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQUENCE_LENGTH = 64\n",
    "WINDOW_OVERLAP = 10\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def sliding_window(seq, window_size, overlap):\n",
    "    for i in range(0, len(seq) - window_size, window_size - overlap):\n",
    "        yield [ tok_to_idx[tok] if tok in tok_to_idx else tok_to_idx['<unk>'] for tok in seq[i:i + window_size] ]\n",
    "\n",
    "\n",
    "## Generate dataset \n",
    "def generate_data(text, seq_length, overlap):\n",
    "    num_tokens = len(char_tokenized_text)\n",
    "    return jnp.array([ seq for seq in sliding_window(char_tokenized_text, seq_length, overlap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3550, 63) Y shape: (3550, 63)\n",
      "Train Dataaset (2840, 63) (2840, 63)\n",
      "Valid Dataset (355, 63) (355, 63)\n",
      "Test Dataset (355, 63) (355, 63)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = generate_data(text, SEQUENCE_LENGTH, WINDOW_OVERLAP)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,1:]\n",
    "\n",
    "\n",
    "train_idxs = list(range(int(0.8*X.shape[0])))\n",
    "valid_idxs = list(range(int(0.8*X.shape[0]), int(0.9*X.shape[0])))\n",
    "test_idxs = list(range(int(0.9*X.shape[0]), X.shape[0]))\n",
    "X_train = X[train_idxs,:]\n",
    "Y_train = Y[train_idxs,:]\n",
    "X_valid = X[valid_idxs,:]\n",
    "Y_valid = Y[valid_idxs,:]\n",
    "X_test = X[test_idxs,:]\n",
    "Y_test = Y[test_idxs,:]\n",
    "\n",
    "assert(X_train.shape[0] + X_valid.shape[0] + X_test.shape[0] == X.shape[0])\n",
    "assert(all(X_valid[i,:].shape[0] == SEQUENCE_LENGTH-1 for i in range(X_valid.shape[0])))\n",
    "\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
    "print(\"Train Dataaset\", X_train.shape, Y_train.shape)\n",
    "print(\"Valid Dataset\", X_valid.shape, Y_valid.shape)\n",
    "print(\"Test Dataset\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's train a single-layer GRU as our baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from blinker import signal\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GRU:Completed epoch=0, train loss=3.5608, valid perplexity=7.9802, elapsed=25.6233s\n",
      "INFO:GRU:Completed epoch=20, train loss=1.9772, valid perplexity=3.8990, elapsed=126.3586s\n",
      "INFO:GRU:Completed epoch=40, train loss=1.7083, valid perplexity=3.3421, elapsed=227.2008s\n",
      "INFO:GRU:Completed epoch=60, train loss=1.5570, valid perplexity=3.1111, elapsed=328.7526s\n",
      "INFO:GRU:Completed epoch=79, train loss=1.4594, valid perplexity=2.9869, elapsed=425.0190s\n"
     ]
    }
   ],
   "source": [
    "from xjax.models import gru\n",
    "\n",
    "logger = logging.getLogger(\"GRU\")\n",
    "\n",
    "# Set up hyperparameters\n",
    "gru_hparams = {\n",
    "    \"hidden_size\":256\n",
    "}\n",
    "gru_train_hparams = {\n",
    "    \"num_epochs\":80,\n",
    "    \"batch_size\":256,\n",
    "    \"learning_rate\":1E-2,\n",
    "    \"max_grad\":1,\n",
    "}\n",
    "\n",
    "params, baseline_model = gru.gru(rng, vocab_size=vocab_size, **gru_hparams)\n",
    "\n",
    "@train_epoch_completed.connect_via(baseline_model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_perplexity, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid perplexity={valid_perplexity:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "baseline_params = gru.train(baseline_model, rng=rng, params=params, \n",
    "                                            X_train=X_train, Y_train=Y_train, \n",
    "                                            X_valid=X_valid, Y_valid=Y_valid, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            **gru_train_hparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add a basic dot-product attention layer as the candidate model\n",
    "We're going to use exactly the same hyperparameters as the baseline model to ensure an apples-to-apples comparison. If our theory is correct, then adding the attention layer should provide a performance boost without having to do any additional tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:GRU+Attn:Completed epoch=0, train loss=3.1477, valid_perplexity=7.4411, elapsed=66.6060s\n",
      "INFO:GRU+Attn:Completed epoch=20, train loss=1.7620, valid_perplexity=3.4132, elapsed=173.1571s\n",
      "INFO:GRU+Attn:Completed epoch=40, train loss=1.4238, valid_perplexity=2.9117, elapsed=281.0839s\n",
      "INFO:GRU+Attn:Completed epoch=49, train loss=1.3379, valid_perplexity=2.8647, elapsed=330.9421s\n"
     ]
    }
   ],
   "source": [
    "from xjax.models import gru_attn\n",
    "\n",
    "logger = logging.getLogger(\"GRU+Attn\")\n",
    "\n",
    "# Set up hyperparameters\n",
    "gru_attn_hparams = {\n",
    "    \"hidden_size\":256\n",
    "}\n",
    "gru_attn_train_hparams = {\n",
    "    \"num_epochs\":50,\n",
    "    \"batch_size\":256,\n",
    "    \"learning_rate\":1E-2,\n",
    "    \"max_grad\":1\n",
    "}\n",
    "\n",
    "params, candidate_model = gru_attn.gru(rng, vocab_size=vocab_size, **gru_attn_hparams)\n",
    "\n",
    "@train_epoch_completed.connect_via(candidate_model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_perplexity, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid_perplexity={valid_perplexity:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model with a dot-product attention layer on the data \n",
    "candidate_params = gru_attn.train(candidate_model, rng=rng, params=params, \n",
    "                                            X_train=X_train, Y_train=Y_train, \n",
    "                                            X_valid=X_valid, Y_valid=Y_valid, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            **gru_attn_train_hparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate some sample sentences from each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xjax\n",
    "\n",
    "# I generate sequences from a prefix\n",
    "prefix_str = \"the time \"\n",
    "prefix = [ tok_to_idx[i] for i in list(prefix_str)]\n",
    "baseline_results = []\n",
    "candidate_results = []\n",
    "for i in range(20):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y_baseline = gru.generate(rng=sub_rng, prefix=prefix, params=baseline_params, \n",
    "                 hidden_size=gru_hparams[\"hidden_size\"], vocab_size=vocab_size, max_len=30) \n",
    "    baseline_results.append(\"\".join([idx_to_tok[i] for i in y_baseline]))\n",
    "    y_candidate = gru_attn.generate(rng=sub_rng, prefix=prefix, params=candidate_params, \n",
    "                 hidden_size=gru_attn_hparams[\"hidden_size\"], vocab_size=vocab_size, max_len=30) \n",
    "    candidate_results.append(\"\".join([idx_to_tok[i] for i in y_candidate]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time e so face dazy the malaus wand        the time e long so dain there was littl\n",
      "the time  ons the apposmed a jourta y a        the time  once it anough down sounaly a\n",
      "the time imal vanage any darkness our i        the time e were began wy mattle balked \n",
      "the time ud any mach i rearn in rilavio        the time e to be vigiefte palloss i som\n",
      "the time kot tertar ve was have eages g        the time  oth even his went and wells g\n",
      "the time ed mach purle may a vast and a        the time et machine but to the sky but \n",
      "the time kless a and the over tient and        the time  leas that i sat who silptence\n",
      "the time  that a just realize adjusing         the time  too faces three fill diffinin\n",
      "the time ikn was a blauch of path by a         the time e of the little all footh year\n",
      "the time naveridg straw purstable even         the time et this not after and took the\n",
      "the time ed i don their munuca this was        the time ew in my eecimilurulion i pass\n",
      "the time ed puzy little with do what i         the time et learte blowbs i trouble of \n",
      "the time  a mach a cand ciever thright         the time  bighting towarciever of man h\n",
      "the time e mear over mile not have been        the time e mere of howing hold in the f\n",
      "the time em of camphorlival mange of su        the time et of common op a telling down\n",
      "the time k shalt to came again a little        the time et halt to chanced more hes of\n",
      "the time ed ago and have you counly i h        the time et and towards the sidued some\n",
      "the time  had do the gamant the rove at        the time  hoove and thime the verous at\n",
      "the time ighat an a have ruil and the l        the time ery bray and flowers heritwonl\n",
      "the time ed falled ammie and a go step         the time er fell as my ewnich and now s\n"
     ]
    }
   ],
   "source": [
    "for b,c in zip(baseline_results, candidate_results):\n",
    "    print(b,\"      \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Perplexity: 4.1332\n",
      "Candidate Perplexity: 3.9717\n"
     ]
    }
   ],
   "source": [
    "baseline_perplexity = xjax.models.gru.perplexity(baseline_model, baseline_params, vocab_size, X_test, Y_test)\n",
    "candidate_perplexity = xjax.models.gru_attn.perplexity(candidate_model, candidate_params, vocab_size, X_test, Y_test)\n",
    "print(f\"Baseline Perplexity: {baseline_perplexity:0.4f}\\nCandidate Perplexity: {candidate_perplexity:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
