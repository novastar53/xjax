{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the performance of Gated Recurrent Units With and Without Attention\n",
    "By learning to predict the text of H.G. Wells' The Time Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('../datasets/timemachine.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/dev/xjax/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = raw_text.lower()\n",
    "text = re.sub(r'[^a-z]+', ' ', text)\n",
    "\n",
    "# Tokenize into characters\n",
    "char_tokenized_text = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s,e, ,i,t, ,u,n,d,e,r, ,t,h,e, ,t,e,r,m,s, ,o,f, ,t,h,e, ,p,r,o,j,e,c,t, ,g,u,t,e,n,b,e,r,g, ,l,i,c,e,n,s,e, ,i,n,c,l,u,d,e,d, ,w,i,t,h, ,t,h,i,s, ,e,b,o,o,k, ,o,r, ,o,n,l,i,n,e, ,a,t, ,w,w,w, ,g,u,t'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(char_tokenized_text[200:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 27\n",
      "  35850\n",
      "e 19667\n",
      "t 15040\n",
      "a 12700\n",
      "i 11254\n",
      "o 11082\n",
      "n 10943\n",
      "s 9242\n",
      "r 8833\n",
      "h 8786\n"
     ]
    }
   ],
   "source": [
    "# Most common tokens\n",
    "from collections import Counter\n",
    "# Flatten the list of tokens\n",
    "# Count the tokens\n",
    "token_counts = Counter(char_tokenized_text)\n",
    "print(f\"Total tokens: {len(token_counts)}\")\n",
    "# Most common tokens\n",
    "most_common_tokens = token_counts.most_common(10)\n",
    "for token, count in most_common_tokens:\n",
    "    print(f\"{token} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 1 ## Minimum token frequency to include in the vocab\n",
    "\n",
    "### Generate the Vocabulary\n",
    "tok_to_idx = {}\n",
    "idx_to_tok =  list(sorted(set(['<unk>'] + [tok for tok,count in token_counts.items() if count >= MIN_FREQ])))\n",
    "tok_to_idx = {tok: idx for idx, tok in enumerate(idx_to_tok)}\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(idx_to_tok)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sliding_window(seq, window_size, overlap):\n",
    "    for i in range(0, len(seq) - window_size, window_size - overlap):\n",
    "        yield [ tok_to_idx[tok] if tok in tok_to_idx else tok_to_idx['<unk>'] for tok in seq[i:i + window_size] ]\n",
    "\n",
    "\n",
    "## Generate dataset \n",
    "def generate_data(text, seq_length, overlap):\n",
    "    num_tokens = len(char_tokenized_text)\n",
    "    return jnp.array([ seq for seq in sliding_window(char_tokenized_text, seq_length, overlap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991, 31) (5991, 31)\n",
      "['p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 's', ' ', 't', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a']\n",
      "['r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 's', ' ', 't', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a', 'c']\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 32\n",
    "WINDOW_OVERLAP = 0\n",
    "\n",
    "data = generate_data(text, SEQUENCE_LENGTH, WINDOW_OVERLAP)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,1:]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print([idx_to_tok[i] for i in X[0]])\n",
    "print([idx_to_tok[i] for i in Y[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Started epoch=0, elapsed=0.0022s\n",
      "INFO:__main__:Completed epoch=0, loss=659.7244, elapsed=14.6347s\n",
      "INFO:__main__:Started epoch=1, elapsed=14.6351s\n",
      "INFO:__main__:Completed epoch=1, loss=568.9825, elapsed=20.3553s\n",
      "INFO:__main__:Started epoch=2, elapsed=20.3558s\n",
      "INFO:__main__:Completed epoch=2, loss=554.8980, elapsed=26.1008s\n",
      "INFO:__main__:Started epoch=3, elapsed=26.1016s\n",
      "INFO:__main__:Completed epoch=3, loss=546.5063, elapsed=32.2924s\n",
      "INFO:__main__:Started epoch=4, elapsed=32.2928s\n",
      "INFO:__main__:Completed epoch=4, loss=543.5025, elapsed=38.1424s\n",
      "INFO:__main__:Started epoch=5, elapsed=38.1430s\n",
      "INFO:__main__:Completed epoch=5, loss=540.0598, elapsed=44.1694s\n",
      "INFO:__main__:Started epoch=6, elapsed=44.1698s\n",
      "INFO:__main__:Completed epoch=6, loss=536.1841, elapsed=49.9213s\n",
      "INFO:__main__:Started epoch=7, elapsed=49.9216s\n",
      "INFO:__main__:Completed epoch=7, loss=536.1277, elapsed=55.6844s\n",
      "INFO:__main__:Started epoch=8, elapsed=55.6848s\n",
      "INFO:__main__:Completed epoch=8, loss=533.6682, elapsed=61.4146s\n",
      "INFO:__main__:Started epoch=9, elapsed=61.4150s\n",
      "INFO:__main__:Completed epoch=9, loss=531.3041, elapsed=67.3494s\n",
      "INFO:__main__:Started epoch=10, elapsed=67.3503s\n",
      "INFO:__main__:Completed epoch=10, loss=532.6061, elapsed=73.1446s\n",
      "INFO:__main__:Started epoch=11, elapsed=73.1449s\n",
      "INFO:__main__:Completed epoch=11, loss=530.0663, elapsed=78.9817s\n",
      "INFO:__main__:Started epoch=12, elapsed=78.9821s\n",
      "INFO:__main__:Completed epoch=12, loss=530.4612, elapsed=84.8167s\n",
      "INFO:__main__:Started epoch=13, elapsed=84.8171s\n",
      "INFO:__main__:Completed epoch=13, loss=528.8727, elapsed=91.0482s\n",
      "INFO:__main__:Started epoch=14, elapsed=91.0495s\n",
      "INFO:__main__:Completed epoch=14, loss=529.3482, elapsed=97.3639s\n",
      "INFO:__main__:Started epoch=15, elapsed=97.3647s\n",
      "INFO:__main__:Completed epoch=15, loss=527.6065, elapsed=103.3791s\n",
      "INFO:__main__:Started epoch=16, elapsed=103.3796s\n",
      "INFO:__main__:Completed epoch=16, loss=528.0659, elapsed=109.5824s\n",
      "INFO:__main__:Started epoch=17, elapsed=109.5859s\n",
      "INFO:__main__:Completed epoch=17, loss=526.3907, elapsed=115.4917s\n",
      "INFO:__main__:Started epoch=18, elapsed=115.4920s\n",
      "INFO:__main__:Completed epoch=18, loss=525.1758, elapsed=121.3969s\n",
      "INFO:__main__:Started epoch=19, elapsed=121.3972s\n",
      "INFO:__main__:Completed epoch=19, loss=526.4841, elapsed=127.2363s\n",
      "INFO:__main__:Started epoch=20, elapsed=127.2366s\n",
      "INFO:__main__:Completed epoch=20, loss=524.5570, elapsed=133.1070s\n",
      "INFO:__main__:Started epoch=21, elapsed=133.1074s\n",
      "INFO:__main__:Completed epoch=21, loss=525.8948, elapsed=139.0168s\n",
      "INFO:__main__:Started epoch=22, elapsed=139.0199s\n",
      "INFO:__main__:Completed epoch=22, loss=525.4565, elapsed=144.8470s\n",
      "INFO:__main__:Started epoch=23, elapsed=144.8474s\n",
      "INFO:__main__:Completed epoch=23, loss=527.8355, elapsed=151.3385s\n",
      "INFO:__main__:Started epoch=24, elapsed=151.3399s\n",
      "INFO:__main__:Completed epoch=24, loss=526.8830, elapsed=157.2171s\n",
      "INFO:__main__:Started epoch=25, elapsed=157.2174s\n",
      "INFO:__main__:Completed epoch=25, loss=525.7559, elapsed=163.0164s\n",
      "INFO:__main__:Started epoch=26, elapsed=163.0168s\n",
      "INFO:__main__:Completed epoch=26, loss=525.4399, elapsed=169.1636s\n",
      "INFO:__main__:Started epoch=27, elapsed=169.1647s\n",
      "INFO:__main__:Completed epoch=27, loss=525.4247, elapsed=175.0290s\n",
      "INFO:__main__:Started epoch=28, elapsed=175.0293s\n",
      "INFO:__main__:Completed epoch=28, loss=525.7764, elapsed=180.8546s\n",
      "INFO:__main__:Started epoch=29, elapsed=180.8550s\n",
      "INFO:__main__:Completed epoch=29, loss=525.6200, elapsed=186.7757s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "\n",
    "from xjax.models import gru\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "HIDDEN_SIZE=32\n",
    "EPOCHS=30\n",
    "LEARNING_RATE = 10**(-2)\n",
    "MAX_GRAD = 2\n",
    "\n",
    "params, model = gru.gru(rng, vocab_size=vocab_size, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "params[0].shape\n",
    "\n",
    "@train_epoch_started.connect_via(model)\n",
    "def collect_events(_, *, epoch, elapsed, **__):\n",
    "    logger.info(f\"Started epoch={epoch}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "@train_epoch_completed.connect_via(model)\n",
    "def collect_events(_, *, epoch, loss, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, loss={loss:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "trained_params = gru.train(model, rng=rng, params=params, \n",
    "                                            X=X, Y=Y, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            batch_size=1024,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xjax\n",
    "\n",
    "# I generate sequences from a prefix\n",
    "prefix_str = \"p\"\n",
    "prefix = [tok_to_idx[c] for c in prefix_str]\n",
    "generated = []\n",
    "for i in range(2):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y = xjax.models.gru.generate(rng=sub_rng, prefix= prefix, params=trained_params, hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, max_len=200) \n",
    "    generated.append(\"\".join([idx_to_tok[i] for i in y]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pales lound about laments gated the quered had uppond the con the confusts just more the reece that the time at fy first were to sto of the more of the saw the rewougher were oull this in be hed of se'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
