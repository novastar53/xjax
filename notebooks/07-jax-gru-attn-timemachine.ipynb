{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Gated Recurrent Units With and Without Attention\n",
    "...by learning to predict the text of H.G. Wells' The Time Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('../datasets/timemachine.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/dev/xjax/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = raw_text.lower()\n",
    "text = re.sub(r'[^a-z]+', ' ', text)\n",
    "\n",
    "# Tokenize into characters\n",
    "char_tokenized_text = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 27\n",
      "  35850\n",
      "e 19667\n",
      "t 15040\n",
      "a 12700\n",
      "i 11254\n",
      "o 11082\n",
      "n 10943\n",
      "s 9242\n",
      "r 8833\n",
      "h 8786\n"
     ]
    }
   ],
   "source": [
    "# Most common tokens\n",
    "from collections import Counter\n",
    "# Flatten the list of tokens\n",
    "# Count the tokens\n",
    "token_counts = Counter(char_tokenized_text)\n",
    "print(f\"Total tokens: {len(token_counts)}\")\n",
    "# Most common tokens\n",
    "most_common_tokens = token_counts.most_common(10)\n",
    "for token, count in most_common_tokens:\n",
    "    print(f\"{token} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 1 ## Minimum token frequency to include in the vocab\n",
    "\n",
    "### Generate the Vocabulary\n",
    "tok_to_idx = {}\n",
    "idx_to_tok =  list(sorted(set(['<unk>'] + [tok for tok,count in token_counts.items() if count >= MIN_FREQ])))\n",
    "tok_to_idx = {tok: idx for idx, tok in enumerate(idx_to_tok)}\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(idx_to_tok)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sliding_window(seq, window_size, overlap):\n",
    "    for i in range(0, len(seq) - window_size, window_size - overlap):\n",
    "        yield [ tok_to_idx[tok] if tok in tok_to_idx else tok_to_idx['<unk>'] for tok in seq[i:i + window_size] ]\n",
    "\n",
    "\n",
    "## Generate dataset \n",
    "def generate_data(text, seq_length, overlap):\n",
    "    num_tokens = len(char_tokenized_text)\n",
    "    return jnp.array([ seq for seq in sliding_window(char_tokenized_text, seq_length, overlap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validate-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8714, 31) (8714, 31)\n",
      "(6971, 31) (6971, 31)\n",
      "(871, 31) (871, 31)\n",
      "(872, 31) (872, 31)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 32\n",
    "WINDOW_OVERLAP = 10 \n",
    "\n",
    "data = generate_data(text, SEQUENCE_LENGTH, WINDOW_OVERLAP)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,1:]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "train_idxs = list(range(int(0.8*X.shape[0])))\n",
    "valid_idxs = list(range(int(0.8*X.shape[0]), int(0.9*X.shape[0])))\n",
    "test_idxs = list(range(int(0.9*X.shape[0]), X.shape[0]))\n",
    "X_train = X[train_idxs,:]\n",
    "Y_train = Y[train_idxs,:]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "X_valid = X[valid_idxs,:]\n",
    "Y_valid = Y[valid_idxs,:]\n",
    "print(X_valid.shape, Y_valid.shape)\n",
    "X_test = X[test_idxs,:]\n",
    "Y_test = Y[test_idxs,:]\n",
    "print(X_test.shape, Y_test.shape)\n",
    "\n",
    "assert(X_train.shape[0] + X_valid.shape[0] + X_test.shape[0] == X.shape[0])\n",
    "assert(all(X_valid[i,:].shape[0] == 31 for i in range(X_valid.shape[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Basic GRU Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed epoch=0, train loss=11.2605, valid perplexity=1.1031, elapsed=8.5733s\n",
      "INFO:__main__:Completed epoch=20, train loss=6.1114, valid perplexity=1.0806, elapsed=39.8160s\n",
      "INFO:__main__:Completed epoch=40, train loss=5.3961, valid perplexity=1.0712, elapsed=70.9211s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "\n",
    "from xjax.models import gru\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "HIDDEN_SIZE=128\n",
    "EPOCHS= 41 #200\n",
    "BATCH_SIZE=128\n",
    "LEARNING_RATE = 2*10**(-3)\n",
    "MAX_GRAD = 1\n",
    "\n",
    "params, baseline_model = gru.gru(rng, vocab_size=vocab_size, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "@train_epoch_completed.connect_via(baseline_model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_perplexity, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid perplexity={valid_perplexity:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "baseline_params = gru.train(baseline_model, rng=rng, params=params, \n",
    "                                            X_train=X_train, Y_train=Y_train, \n",
    "                                            X_valid=X_valid, Y_valid=Y_valid, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Basic GRU + Basic Dot-Product Self-Attention Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed epoch=0, train loss=10.4208, valid_perplexity=1.1045, elapsed=17.8992s\n",
      "INFO:__main__:Completed epoch=20, train loss=5.8326, valid_perplexity=1.0768, elapsed=60.0325s\n",
      "INFO:__main__:Completed epoch=40, train loss=5.0064, valid_perplexity=1.0664, elapsed=102.7881s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "from xjax.models import gru_attn\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "HIDDEN_SIZE=128\n",
    "EPOCHS=41 #200\n",
    "BATCH_SIZE=128\n",
    "LEARNING_RATE = 2*10**(-3)\n",
    "MAX_GRAD = 1\n",
    "\n",
    "params, candidate_model = gru_attn.gru(rng, vocab_size=vocab_size, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "@train_epoch_completed.connect_via(candidate_model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_perplexity, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid_perplexity={valid_perplexity:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "candidate_params = gru_attn.train(candidate_model, rng=rng, params=params, \n",
    "                                            X_train=X_train, Y_train=Y_train, \n",
    "                                            X_valid=X_valid, Y_valid=Y_valid, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xjax\n",
    "\n",
    "# I generate sequences from a prefix\n",
    "prefix_str = \"the time\"\n",
    "prefix = [ tok_to_idx[i] for i in list(prefix_str)]\n",
    "generated = []\n",
    "for i in range(20):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y = gru_attn.generate(rng=sub_rng, prefix=prefix, params=candidate_params, \n",
    "                 hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, max_len=30) \n",
    "    generated.append(\"\".join([idx_to_tok[i] for i in y]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the timetfriih a n yiirepy afaorl an<unk>n\n",
      "the time   ei slcuahtwdtrf rs hr hyen \n",
      "the timeaibiono  aa a w g  nuxoo ts g \n",
      "the timecsaarn  el  norhq oodr rdxe  c\n",
      "the timeihelhldvdt  rte h uopeedotrd d\n",
      "the timeneennre n t tits tr  ynwir doh\n",
      "the timemtiw    rfst re es  trm stpw n\n",
      "the time  ix eot m egevnoy ou   g de r\n",
      "the timemhd  voa    ne o n elgo oo ira\n",
      "the timet oaiauneo hroo xi ssi ltgt i \n",
      "the timeaekceps  etsaiymohchecae  ra h\n",
      "the time ttiiulesht eia a bhhswe ud hs\n",
      "the timed   aoi  t ao mi ksweh  ul f v\n",
      "the time i  a a msnhut    frkexateo de\n",
      "the timer o feamemh t eei ndhd n e  a \n",
      "the timeuhiagtw thyinltb  ards oi ssat\n",
      "the timeupeosew  ahn  ieo i henot wiit\n",
      "the timealnn emrtaohh  dheodls frd aeh\n",
      "the timezg  ddn n ynllaecetwndo  met a\n",
      "the time gce etoolc  fuhnssxysorwhl a \n"
     ]
    }
   ],
   "source": [
    "for g in generated:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Perplexity: 1.0800\n",
      "Candidate Perplexity: 1.0770\n"
     ]
    }
   ],
   "source": [
    "baseline_perplexity = xjax.models.gru.perplexity(baseline_model, baseline_params, vocab_size, X_test, Y_test)\n",
    "candidate_perplexity = xjax.models.gru_attn.perplexity(candidate_model, candidate_params, vocab_size, X_test, Y_test)\n",
    "print(f\"Baseline Perplexity: {baseline_perplexity:0.4f}\\nCandidate Perplexity: {candidate_perplexity:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
