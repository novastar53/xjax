{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the performance of Gated Recurrent Units With and Without Attention\n",
    "By learning to predict the text of H.G. Wells' The Time Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('../datasets/timemachine.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/dev/xjax/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = raw_text.lower()\n",
    "text = re.sub(r'[^a-z]+', ' ', text)\n",
    "\n",
    "# Tokenize into characters\n",
    "char_tokenized_text = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s,e, ,i,t, ,u,n,d,e,r, ,t,h,e, ,t,e,r,m,s, ,o,f, ,t,h,e, ,p,r,o,j,e,c,t, ,g,u,t,e,n,b,e,r,g, ,l,i,c,e,n,s,e, ,i,n,c,l,u,d,e,d, ,w,i,t,h, ,t,h,i,s, ,e,b,o,o,k, ,o,r, ,o,n,l,i,n,e, ,a,t, ,w,w,w, ,g,u,t'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(char_tokenized_text[200:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 27\n",
      "  35850\n",
      "e 19667\n",
      "t 15040\n",
      "a 12700\n",
      "i 11254\n",
      "o 11082\n",
      "n 10943\n",
      "s 9242\n",
      "r 8833\n",
      "h 8786\n"
     ]
    }
   ],
   "source": [
    "# Most common tokens\n",
    "from collections import Counter\n",
    "# Flatten the list of tokens\n",
    "# Count the tokens\n",
    "token_counts = Counter(char_tokenized_text)\n",
    "print(f\"Total tokens: {len(token_counts)}\")\n",
    "# Most common tokens\n",
    "most_common_tokens = token_counts.most_common(10)\n",
    "for token, count in most_common_tokens:\n",
    "    print(f\"{token} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 1 ## Minimum token frequency to include in the vocab\n",
    "\n",
    "### Generate the Vocabulary\n",
    "tok_to_idx = {}\n",
    "idx_to_tok =  list(sorted(set(['<unk>'] + [tok for tok,count in token_counts.items() if count >= MIN_FREQ])))\n",
    "tok_to_idx = {tok: idx for idx, tok in enumerate(idx_to_tok)}\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(idx_to_tok)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sliding_window(seq, window_size, overlap):\n",
    "    for i in range(0, len(seq) - window_size, window_size - overlap):\n",
    "        yield [ tok_to_idx[tok] if tok in tok_to_idx else tok_to_idx['<unk>'] for tok in seq[i:i + window_size] ]\n",
    "\n",
    "\n",
    "## Generate dataset \n",
    "def generate_data(text, seq_length, overlap):\n",
    "    num_tokens = len(char_tokenized_text)\n",
    "    return jnp.array([ seq for seq in sliding_window(char_tokenized_text, seq_length, overlap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991, 31) (5991, 31)\n",
      "['p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 's', ' ', 't', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a']\n",
      "['r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 's', ' ', 't', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a', 'c']\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 32\n",
    "WINDOW_OVERLAP = 0\n",
    "\n",
    "data = generate_data(text, SEQUENCE_LENGTH, WINDOW_OVERLAP)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,1:]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print([idx_to_tok[i] for i in X[0]])\n",
    "print([idx_to_tok[i] for i in Y[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Started epoch=0, elapsed=0.0153s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "\n",
    "from xjax.models import gru\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "HIDDEN_SIZE=32\n",
    "EPOCHS=50\n",
    "LEARNING_RATE = 10**(-2)\n",
    "MAX_GRAD = 1\n",
    "\n",
    "params, model = gru.gru(rng, vocab_size=vocab_size, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "params[0].shape\n",
    "\n",
    "@train_epoch_started.connect_via(model)\n",
    "def collect_events(_, *, epoch, elapsed, **__):\n",
    "    logger.info(f\"Started epoch={epoch}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "@train_epoch_completed.connect_via(model)\n",
    "def collect_events(_, *, epoch, loss, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, loss={loss:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "trained_params = gru.train(model, rng=rng, params=params, \n",
    "                                            X=X, Y=Y, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            batch_size=1024,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xjax\n",
    "\n",
    "# I generate sequences from a prefix\n",
    "prefix_str = \"p\"\n",
    "prefix = [tok_to_idx[c] for c in prefix_str]\n",
    "generated = []\n",
    "for i in range(1):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y = xjax.models.gru.generate(rng=sub_rng, prefix= prefix, params=trained_params, hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, max_len=200) \n",
    "    generated.append(\"\".join([idx_to_tok[i] for i in y]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pass that and out then the interps the with very proth that the enthing this a brown was with the slaid and i f decont a on the inthinnt of the eanisk in other agaces a folder the out hung will appear'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
