{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Gated Recurrent Units With and Without Attention\n",
    "...by learning to predict the text of H.G. Wells' The Time Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('../datasets/timemachine.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's tokenize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Remove punctuation and convert to lowercase\n",
    "text = raw_text.lower()\n",
    "text = re.sub(r'[^a-z]+', ' ', text)\n",
    "\n",
    "# Tokenize into characters\n",
    "char_tokenized_text = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s,e, ,i,t, ,u,n,d,e,r, ,t,h,e, ,t,e,r,m,s, ,o,f, ,t,h,e, ,p,r,o,j,e,c,t, ,g,u,t,e,n,b,e,r,g, ,l,i,c,e,n,s,e, ,i,n,c,l,u,d,e,d, ,w,i,t,h, ,t,h,i,s, ,e,b,o,o,k, ,o,r, ,o,n,l,i,n,e, ,a,t, ,w,w,w, ,g,u,t'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(char_tokenized_text[200:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 27\n",
      "  35850\n",
      "e 19667\n",
      "t 15040\n",
      "a 12700\n",
      "i 11254\n",
      "o 11082\n",
      "n 10943\n",
      "s 9242\n",
      "r 8833\n",
      "h 8786\n"
     ]
    }
   ],
   "source": [
    "# Most common tokens\n",
    "from collections import Counter\n",
    "# Flatten the list of tokens\n",
    "# Count the tokens\n",
    "token_counts = Counter(char_tokenized_text)\n",
    "print(f\"Total tokens: {len(token_counts)}\")\n",
    "# Most common tokens\n",
    "most_common_tokens = token_counts.most_common(10)\n",
    "for token, count in most_common_tokens:\n",
    "    print(f\"{token} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 1 ## Minimum token frequency to include in the vocab\n",
    "\n",
    "### Generate the Vocabulary\n",
    "tok_to_idx = {}\n",
    "idx_to_tok =  list(sorted(set(['<unk>'] + [tok for tok,count in token_counts.items() if count >= MIN_FREQ])))\n",
    "tok_to_idx = {tok: idx for idx, tok in enumerate(idx_to_tok)}\n",
    "\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(idx_to_tok)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sliding_window(seq, window_size, overlap):\n",
    "    for i in range(0, len(seq) - window_size, window_size - overlap):\n",
    "        yield [ tok_to_idx[tok] if tok in tok_to_idx else tok_to_idx['<unk>'] for tok in seq[i:i + window_size] ]\n",
    "\n",
    "\n",
    "## Generate dataset \n",
    "def generate_data(text, seq_length, overlap):\n",
    "    num_tokens = len(char_tokenized_text)\n",
    "    return jnp.array([ seq for seq in sliding_window(char_tokenized_text, seq_length, overlap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validate-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8714, 31) (8714, 31)\n",
      "(6971, 31) (6971, 31)\n",
      "(871, 31) (871, 31)\n",
      "(872, 31) (872, 31)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 32\n",
    "WINDOW_OVERLAP = 10 \n",
    "\n",
    "data = generate_data(text, SEQUENCE_LENGTH, WINDOW_OVERLAP)\n",
    "X = data[:,:-1]\n",
    "Y = data[:,1:]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "train_idxs = list(range(int(0.8*X.shape[0])))\n",
    "valid_idxs = list(range(int(0.8*X.shape[0]), int(0.9*X.shape[0])))\n",
    "test_idxs = list(range(int(0.9*X.shape[0]), X.shape[0]))\n",
    "X_train = X[train_idxs,:]\n",
    "Y_train = Y[train_idxs,:]\n",
    "print(X_train.shape, Y_train.shape)\n",
    "X_valid = X[valid_idxs,:]\n",
    "Y_valid = Y[valid_idxs,:]\n",
    "print(X_valid.shape, Y_valid.shape)\n",
    "X_test = X[test_idxs,:]\n",
    "Y_test = Y[test_idxs,:]\n",
    "print(X_test.shape, Y_test.shape)\n",
    "\n",
    "assert(X_train.shape[0] + X_valid.shape[0] + X_test.shape[0] == X.shape[0])\n",
    "assert(all(X_valid[i,:].shape[0] == 31 for i in range(X_valid.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Completed epoch=0, train loss=37.3494, valid loss=0.1404, elapsed=13.0957s\n",
      "INFO:__main__:Completed epoch=20, train loss=21.2666, valid loss=0.0975, elapsed=85.4223s\n",
      "INFO:__main__:Completed epoch=40, train loss=18.7488, valid loss=0.0879, elapsed=158.1976s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from blinker import signal\n",
    "\n",
    "import jax\n",
    "\n",
    "from xjax.models import gru\n",
    "from xjax.signals import train_epoch_started, train_epoch_completed\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "HIDDEN_SIZE=128\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE = 10**(-3)\n",
    "MAX_GRAD = 1\n",
    "\n",
    "params, model = gru.gru(rng, vocab_size=vocab_size, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "@train_epoch_completed.connect_via(model)\n",
    "def collect_events(_, *, epoch, train_loss, valid_loss, elapsed, **__):\n",
    "    logger.info(f\"Completed epoch={epoch}, train loss={train_loss:0.4f}, valid loss={valid_loss:0.4f}, elapsed={elapsed:0.4f}s\")\n",
    "\n",
    "\n",
    "# I train a GRU model on the data \n",
    "trained_params = gru.train(model, rng=rng, params=params, \n",
    "                                            X_train=X_train, Y_train=Y_train, \n",
    "                                            X_valid=X_valid, Y_valid=Y_valid, \n",
    "                                            vocab_size=vocab_size, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            num_epochs=EPOCHS, \n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            max_grad=MAX_GRAD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xjax\n",
    "\n",
    "# I generate sequences from a prefix\n",
    "prefix_str = \"i saw\"\n",
    "prefix = [ tok_to_idx[i] for i in list(prefix_str)]\n",
    "generated = []\n",
    "for i in range(20):\n",
    "    rng, sub_rng = jax.random.split(rng)\n",
    "    y = gru.generate(rng=sub_rng, prefix=prefix, params=trained_params, \n",
    "                 hidden_size=HIDDEN_SIZE, vocab_size=vocab_size, max_len=20) \n",
    "    generated.append(\"\".join([idx_to_tok[i] for i in y]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i saw and down the perhap\n",
      "i saw no solute you the p\n",
      "i saw the time as in the \n",
      "i saw was is a potward of\n",
      "i saw the thing to my min\n",
      "i saw the running but was\n",
      "i saw must was the bit my\n",
      "i saw the interest of fin\n",
      "i saw the actual and diff\n",
      "i saw was that sowe went \n",
      "i saw at ground and white\n",
      "i saw that the down i saw\n",
      "i saw the time stread has\n",
      "i saw you know the than h\n",
      "i saw the sky little pazz\n",
      "i saw a perfect no potent\n",
      "i saw increass the adreac\n",
      "i saw was fire for rested\n",
      "i saw was other human sen\n",
      "i saw in the stunly the d\n"
     ]
    }
   ],
   "source": [
    "for g in generated:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Perplexity on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
